{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "JSON Conversion of Network Entities using Python Standard Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For storage and sharing of network design and analysis information we will be using JSON (Javascrip Object Notation). This is a standardized file and transfer format and more information can be found at <http://www.json.org>.\n",
    "\n",
    "Idea: Python can read and write JSON strings and files.  However that doesn't mean it understands what you intend to do with the JSON. Furthermore Python has many more and more powerful data structures than JSON supports (JSON is kept intentionally simple). Hence we will be pre-processing and post-processing in the JSON export and JSON import processes repectively to get the best features of both Python and JSON.\n",
    "\n",
    "Some of the output panes have been minimized. Use a single click to expand them and a double click to minimize them again.\n",
    "\n",
    "The first thing to do is import the json module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Saving and Reading Demand Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following hypothetical demand dictionary for a three node network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demands = {(1, 2): 5, (1, 3): 7, (2, 1): 5, (2, 3): 8, (3, 1): 7, (3, 2): 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to naively convert this to a JSON string we get the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "keys must be a string",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7a20caf4ca63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdemands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, encoding, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         encoding == 'utf-8' and default is None and not sort_keys and not kw):\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\json\\encoder.pyc\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;31mTypeError\u001b[0m: keys must be a string"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print json.dumps(demands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up the json.dumps function tells us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dumps in module json:\n",
      "\n",
      "dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding='utf-8', default=None, sort_keys=False, **kw)\n",
      "    Serialize ``obj`` to a JSON formatted ``str``.\n",
      "    \n",
      "    If ``skipkeys`` is false then ``dict`` keys that are not basic types\n",
      "    (``str``, ``unicode``, ``int``, ``long``, ``float``, ``bool``, ``None``)\n",
      "    will be skipped instead of raising a ``TypeError``.\n",
      "    \n",
      "    If ``ensure_ascii`` is false, all non-ASCII characters are not escaped, and\n",
      "    the return value may be a ``unicode`` instance. See ``dump`` for details.\n",
      "    \n",
      "    If ``check_circular`` is false, then the circular reference check\n",
      "    for container types will be skipped and a circular reference will\n",
      "    result in an ``OverflowError`` (or worse).\n",
      "    \n",
      "    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n",
      "    strict compliance of the JSON specification, instead of using the\n",
      "    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "    \n",
      "    If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "    object members will be pretty-printed with that indent level. An indent\n",
      "    level of 0 will only insert newlines. ``None`` is the most compact\n",
      "    representation.  Since the default item separator is ``', '``,  the\n",
      "    output might include trailing whitespace when ``indent`` is specified.\n",
      "    You can use ``separators=(',', ': ')`` to avoid this.\n",
      "    \n",
      "    If ``separators`` is an ``(item_separator, dict_separator)`` tuple\n",
      "    then it will be used instead of the default ``(', ', ': ')`` separators.\n",
      "    ``(',', ':')`` is the most compact JSON representation.\n",
      "    \n",
      "    ``encoding`` is the character encoding for str instances, default is UTF-8.\n",
      "    \n",
      "    ``default(obj)`` is a function that should return a serializable version\n",
      "    of obj or raise TypeError. The default simply raises TypeError.\n",
      "    \n",
      "    If *sort_keys* is ``True`` (default: ``False``), then the output of\n",
      "    dictionaries will be sorted by key.\n",
      "    \n",
      "    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "    ``.default()`` method to serialize additional types), specify it with\n",
      "    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json.dumps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Although* it looks like the `default` function should be able to help us out with the conversion, this is not the case for a standard type like a dictionary (dict) since it ignores the `default` function and repeats the error.\n",
    "\n",
    "An alternative approach is to just define a helper function that takes us a bit farther towards the final JSON format that we'd like without doing everything from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demands_to_j(obj):\n",
    "    \"\"\" A function to partially convert a demand dictionary to JSON format.\"\"\"\n",
    "    tmp = []\n",
    "    for d in obj.keys():\n",
    "        tmp.append({\"source\": d[0], \"target\": d[1], \"demand\": obj[d]})\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can obtain a nice JSON representation of our demand dictionary as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"source\": 1, \"target\": 2, \"demand\": 5}, {\"source\": 3, \"target\": 2, \"demand\": 8}, {\"source\": 1, \"target\": 3, \"demand\": 7}, {\"source\": 3, \"target\": 1, \"demand\": 7}, {\"source\": 2, \"target\": 1, \"demand\": 5}, {\"source\": 2, \"target\": 3, \"demand\": 8}]\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(demands_to_j(demands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several keyword arguments we can feed to `json.dumps` to give us nicer human readable output. These include `sort_keys` and `indent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"demand\": 5, \"source\": 1, \"target\": 2}, {\"demand\": 8, \"source\": 3, \"target\": 2}, {\"demand\": 7, \"source\": 1, \"target\": 3}, {\"demand\": 7, \"source\": 3, \"target\": 1}, {\"demand\": 5, \"source\": 2, \"target\": 1}, {\"demand\": 8, \"source\": 2, \"target\": 3}]\n",
      "Now with indentation\n",
      "[\n",
      "    {\n",
      "        \"demand\": 5, \n",
      "        \"source\": 1, \n",
      "        \"target\": 2\n",
      "    }, \n",
      "    {\n",
      "        \"demand\": 8, \n",
      "        \"source\": 3, \n",
      "        \"target\": 2\n",
      "    }, \n",
      "    {\n",
      "        \"demand\": 7, \n",
      "        \"source\": 1, \n",
      "        \"target\": 3\n",
      "    }, \n",
      "    {\n",
      "        \"demand\": 7, \n",
      "        \"source\": 3, \n",
      "        \"target\": 1\n",
      "    }, \n",
      "    {\n",
      "        \"demand\": 5, \n",
      "        \"source\": 2, \n",
      "        \"target\": 1\n",
      "    }, \n",
      "    {\n",
      "        \"demand\": 8, \n",
      "        \"source\": 2, \n",
      "        \"target\": 3\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(demands_to_j(demands), sort_keys=True)\n",
    "print \"Now with indentation\"\n",
    "print json.dumps(demands_to_j(demands), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read a JSON representation of demands and turn it into a demand dictionary we can reverse the process. Once again we'll use a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON demand string, we use a \"\\\" to break a long string into multiple lines.\n",
    "demand_string = '[{\"source\": 1, \"target\": 2, \"demand\": 5}, {\"source\": 3, \"target\": 2, \"demand\": 8},\\\n",
    "{\"source\": 1, \"target\": 3, \"demand\": 7}, {\"source\": 3, \"target\": 1, \"demand\": 7},\\\n",
    "{\"source\": 2, \"target\": 1, \"demand\": 5}, {\"source\": 2, \"target\": 3, \"demand\": 8}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'source': 1, u'target': 2, u'demand': 5}, {u'source': 3, u'target': 2, u'demand': 8}, {u'source': 1, u'target': 3, u'demand': 7}, {u'source': 3, u'target': 1, u'demand': 7}, {u'source': 2, u'target': 1, u'demand': 5}, {u'source': 2, u'target': 3, u'demand': 8}]\n"
     ]
    }
   ],
   "source": [
    "# Try deserializing the above JSON string\n",
    "p_demand = json.loads(demand_string)\n",
    "print p_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_to_demands(d_list):\n",
    "    \"\"\" Helps read in a demand dictionary from a JSON object.\n",
    "        Assumes that d_list is a list of Python dictionaries representing the\n",
    "        JSON demand and has from, to, and volume keys.\n",
    "    \"\"\"\n",
    "    tmp = {}\n",
    "    for d in d_list:\n",
    "        tmp[d[\"source\"], d[\"target\"]] = d[\"demand\"]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 2): 5, (3, 2): 8, (1, 3): 7, (3, 1): 7, (2, 1): 5, (2, 3): 8}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Try deserializing the above JSON string\n",
    "demands2 = j_to_demands(json.loads(demand_string))\n",
    "print demands2\n",
    "print demands2 == demands"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Candidate Path Dictionaries: Writing and Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a *link-path* formulation for network design problems we need a list of candidate paths. Furthermore it is very convenient to organize these by which demand pairs apply. We will use a node list representation for a path, and  have a list of candidate paths per demand pair.\n",
    "\n",
    "For a simple three node network we could have a candidate path dictionary that looks something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {(1, 2): [[1, 2], [1, 3, 2]],\n",
    " (1, 3): [[1, 3], [1, 2, 3]],\n",
    " (2, 1): [[2, 1]],\n",
    " (2, 3): [[2, 3]],\n",
    " (3, 1): [[3, 1], [3, 2, 1]],\n",
    " (3, 2): [[3, 2]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python tuples don't always need to be in parenthesis so we can get a list of paths for a demand with simple syntax such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3], [1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "print paths[1,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert to a nice JSON form we'll use a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_j(path_dict):\n",
    "    \"Takes a candidate paths dictionary and converts it to a JSON serializable form.\"\n",
    "    tmp = []  # We'll use a list\n",
    "    for k in path_dict.keys(): \n",
    "        tmp.append({\"source\": k[0], \"target\": k[1], \"paths\": path_dict[k]})\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"source\": 1, \"target\": 2, \"paths\": [[1, 2], [1, 3, 2]]}, {\"source\": 3, \"target\": 2, \"paths\": [[3, 2]]}, {\"source\": 1, \"target\": 3, \"paths\": [[1, 3], [1, 2, 3]]}, {\"source\": 3, \"target\": 1, \"paths\": [[3, 1], [3, 2, 1]]}, {\"source\": 2, \"target\": 1, \"paths\": [[2, 1]]}, {\"source\": 2, \"target\": 3, \"paths\": [[2, 3]]}]\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(paths_to_j(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create helper function to go from JSON to a candidate path dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_to_paths(path_list):\n",
    "    \"\"\" A helper function to retreive a candidate path dictionary from JSON\n",
    "        Assumes that path_list is a list of dictionaries, each representing a JSON path candidate\n",
    "        object with from, to, and paths keywords.\n",
    "    \"\"\"\n",
    "    tmp = {}\n",
    "    for p in path_list:\n",
    "        tmp[p[\"source\"],p[\"target\"]] = p[\"paths\"]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example JSON string for candidate paths\n",
    "path_string = '[{\"target\": 2, \"source\": 1, \"paths\": [[1, 2], [1, 3, 2]]}, \\\n",
    "{\"target\": 2, \"source\": 3, \"paths\": [[3, 2]]}, {\"target\": 3, \"source\": 1, \"paths\": [[1, 3], [1, 2, 3]]},\\\n",
    "{\"target\": 1, \"source\": 3, \"paths\": [[3, 1], [3, 2, 1]]}, {\"target\": 1, \"source\": 2, \"paths\": [[2, 1]]},\\\n",
    "{\"target\": 3, \"source\": 2, \"paths\": [[2, 3]]}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{(1, 2): [[1, 2], [1, 3, 2]], (3, 2): [[3, 2]], (1, 3): [[1, 3], [1, 2, 3]], (3, 1): [[3, 1], [3, 2, 1]], (2, 1): [[2, 1]], (2, 3): [[2, 3]]}\n"
     ]
    }
   ],
   "source": [
    "# Try converting from JSON path string back to a candidate path dictionary\n",
    "paths2 = j_to_paths(json.loads(path_string))\n",
    "print paths == paths2\n",
    "print paths2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "name": "",
  "signature": "sha256:eca98cbf3bc2716053f5e8caf1df5a0bc406386045cbd9ab7cd849653e39c553"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
